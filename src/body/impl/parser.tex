\documentclass[../../../main.tex]{subfiles}

\begin{document}

\section{Representing and Simplifying Parsers}\label{sec:parser-representation}
\TODO{
  This is an INTERMEDIATE SYMBOLIC REPRESENTATION (?)
  more specialised than general-purpose scala ast
  This section is about simplifying in our semantic domain (parsers)

Scalafix runs at the meta-level, outside of the phase distinction of compile- and run-time.
Staged metaprogramming applies optimisations at compile-time, whereas these ``optimisations'' at applied post-compilation
}

% TODO: come back to this after the section body is finished
% Several of the more complex lint rules, most notably \cref{sec:factor-leftrec}, require manipulating parser combinators in a high-level manner.

% TODO: our parser representation is akin to Haskell parsley's deep-embedded combinator tree, albeit representing all combinators rather than just the core ones

For example, given two \textsc{ast} nodes \scala{Term.Name("p")} and \scala{Term.Name("q")} corresponding to named parsers \scala{p} and \scala{q}, suppose a transformation involves combining them with the \emph{ap} combinator \scala{<*>}.
One may consider using quasiquotes to achieve this: \scala{q"p <*> q"} would automatically expand to \scala{Term.ApplyInfix(Term.Name("p"), Term.Name("<*>"), Type.ArgClause(Nil), Term.ArgClause(List(Term.Name("q")), None))}.
However, this loses the static inspectability of the individual parsers \scala{p} and \scala{q} -- although quasiquotes can be used as extractor patterns to recover the original \textsc{ast} nodes, their usage as such is discouraged as they can easily result in unintended match errors. % TODO: cite? footnote? https://scalameta.org/docs/trees/guide.html#with-quasiquotes-1
The recommended approach is to pattern match on the \textsc{ast} nodes directly, which is obviously unergonomic even for this small example: to extract the \textsc{rhs} term \scala{q}, one would have to perform a nested pattern match on the \scala{Term.ApplyInfix} term and its \scala{Term.ArgClause} node representing the arguments of the infix function application.

It is hopefully obvious that this would a very painful process for the rule author.
It would be desirable to abstract away from the low-level syntactic \textsc{ast} representation, and instead treat these \textsc{ast} nodes as what they semantically represent -- parsers.

Instead, \cref{fig:parser-adt} shows how parser terms can be represented as an algebraic data type \textsc{adt}, in the same way \texttt{parsley} itself uses a deep embedding to represent parsers as pure data objects.
The reasoning behind this approach is the same as that for \textsc{parsley} -- this representation allows parsers to be easily inspected and analysed via pattern matching on constructors.

\begin{figure}[htbp]
\begin{minted}{scala}
trait Parser
case class NonTerminal(ref: Symbol) extends Parser
case class Pure(f: Function) extends Parser
case object Empty extends Parser
case class Choice(p: Parser, q: Parser) extends Parser
case class Ap(p: Parser, q: Parser) extends Parser
...
\end{minted}
\caption{A subset of the core combinators in the \scala{Parser} \textsc{adt}.}
\label{fig:parser-adt}
\end{figure}

% Instead, represent parsers as an algebraic data type \textsc{adt} in the same way that Parsley itself uses a deep embedding to represent combinators as objects.
% Methods on these objects can then be used to manipulate them, and the resulting object can still be pattern matched, maintaining the static inspectability of the parsers.
% So then it's just like writing parsers in Parsley itself: \scala{p <*> q} constructs a \scala{Ap(p, q)} node which can still be pattern matched on.
% And similar to Parsley, representing everything as objects makes it easy to optimise using pattern matching on constructors.
% This representation also then gives us for free the implementation for lint rules such as \emph{Simplify Complex Parsers} rule, which applies parser laws to simplify parsers.

This \namecref{sec:parser-representation} explores the motivation behind this and the design choices made in the implementation.
Use the left-recursion factoring~(\cref{sec:factor-leftrec}) rule as a basis/context to demonstrate the utility of this representation.

% TODO: fix the above "intro" ------------------------------------------------------------------------------

\paragraph{Running example}
The left-recursion factoring rule~(\cref{sec:factor-leftrec}) performs the most complex analyses and transformations on parsers in \texttt{parsley-garnish}.
Thus, it is a good example to motivate the design requirements for the parser representation.
The following left-recursive parser and its transformation into its \scala{postfix} form will serve as a running example for this \namecref{sec:parser-representation}:
\begin{minted}{scala}
lazy val expr: Parsley[String] = (expr, string("a")).zipped(_ + _) | string("b")
\end{minted}

\subsection{Detecting Named Parsers}
Before any analysis on parsers can be performed, it is first necessary to identify which \textsc{ast} nodes correspond to parsers.
\texttt{parsley-garnish} builds a map of all parsers defined within a source file, indexed by the unique symbol of its name.

Identifying these \textsc{ast} nodes of interest involves pattern matching on \scala{val}, \scala{var}, and \scala{def} definitions with a type inferred to be some \scala{Parsley[_]} -- this information is accessed by querying the Scalafix semantic \textsc{api} for the node's symbol information.
% In this example, the type of \scala{expr} is explicitly given as the Scala compiler requires this due to being a recursive definition.
Consider the labelled \scala{ast} structure of the \scala{expr} parser:
\begin{minted}{scala}
Defn.Val(
  mods = List(Mod.Lazy()),
  pats = List(Pat.Var(Term.Name("expr"))),
  decltpe = Some(
    Type.Apply(Type.Name("Parsley"), Type.ArgClause(List(Type.Name("String"))))
  ),
  rhs = Term.ApplyInfix(...)
)
\end{minted}
%
The qualified symbol \scala{expr} is used as the key in the map, and the \scala{rhs} term is lifted the intermediate parser representation for analysis.
A reference to the original \textsc{ast} node is also kept so any lint diagnostics or code rewrites can be applied to the correct location in the source file.
Thus, a full traversal through the source file builds a map of all named parsers, representing all non-terminals in the grammar defined within that file.

\subsection{Converting Scalameta Terms to the Parser \textsc{adt}}
Having identified the \textsc{ast} nodes which represent parsers, they need to be transformed into the appropriate \scala{Parser} representation.
This involves pattern matching on the \scala{scala.meta.Term} to determine which parser combinator it represents, and then constructing the appropriate \scala{Parser} instance.

Each \scala{Parser} defines a partial function, \scala{fromTerm}, which creates an instance of that parser from the appropriate \scala{scala.meta.Term}.
These \scala{fromTerm} methods are combined to define a \scala{toParser} extension method on \scala{scala.meta.Term} -- this is where \textsc{ast} nodes are lifted to their corresponding \scala{Parser} representation.
% Use Scalafix's \scala{SymbolMatcher} to match tree nodes that resolve to a specific set of symbols.
% This makes use of semantic information from SemanticDB, so we are sure that a \scala{<*>} is actually within the \scala{parsley.Parsley} package, rather than some other function with the same name.
% This is much more robust compared to HLint, which suffers from false positives due to its reliance on syntactic information only.

The top-level combinator that makes up \scala{expr}'s definition is the choice combinator, \scala{|}.
Scalameta represents this infix application of the \scala{|} operator as so:
\begin{minted}{scala}
Term.ApplyInfix(
  lhs = Term.Apply(...), // AST node for (expr, string("a")).zipped(_ + _)
  op = Term.Name("|"),
  targClause = Type.ArgClause(List()),
  argClause = Term.ArgClause(
    List(
      Term.Apply(
        Term.Name("string"),
        Term.ArgClause(List(Lit.String("b")), None)
      )
    ),
    None
  )
)
\end{minted}
%
This structure therefore guides the implementation of the pattern match in \scala{Choice.fromTerm}:
\begin{minted}{scala}
object Choice {
  val matcher = SymbolMatcher.normalized("parsley.Parsley.`|`", "parsley.Parsley.`<|>`")

  def fromTerm(implicit doc: SemanticDocument): PartialFunction[Term, Choice] = {
    case Term.ApplyInfix(p, matcher(_), _, Term.ArgClause(List(q), _)) =>
      Choice(p.toParser, q.toParser)
  }
}
\end{minted}
%
The definition of this method is fairly self-explanatory: it matches on a \scala{ApplyInfix} term where the operator is the \scala{|} combinator, and recursively applies \scala{toParser} to its \textsc{lhs} and \textsc{rhs} nodes.
Finishing off, the \scala{expr} parser is therefore converted to the following \scala{Parser} instance:
% Choice(
%   Zipped(Function(_ + _), List(NonTerminal(expr), Str(a))),
%   Str(b)
% )
\begin{minted}[escapeinside=\%\%]{scala}
Choice(
  Zipped(%\textcolor{gray}{Function(\_ + \_)}%, List(NonTerminal(expr), Str(a))),
  Str(b)
)
\end{minted}
The exact representation of the \scala{Function} is not important at this momenet -- this is covered in the next \namecref{sec:function-representation}.
For brevity, the remaining code snippets in this \namecref{sec:parser-representation} will simplify the function representations and continue to grey them out.

\subsection{Building New Parsers From Existing Parsers}
Now that raw \textsc{ast} terms can be lifted to the higher-level parser representation, it is easy to build new parsers from existing parsers.
This is crucial for left-recursion factoring, which ``unfolds'' parsers into separate parsers representing the left-recursive and non-left-recursive parts.
These are then recombined to form parsers which are free from left recursion.

Smart constructors are used to make manipulating parser terms resemble writing \texttt{parsley} code itself.
These are defined as infix operators, which are written as extension methods on the \scala{Parser} trait:
\begin{minted}{scala}
implicit class ParserOps(private val p: Parser) extends AnyVal {
  def <*>(q: Parser): Parser = Ap(p, q)
  def <|>(q: Parser): Parser = Choice(p, q)
  def map(f: Function): Parser = FMap(p, f)
}
\end{minted}
%
Parser terms can now be manipulated in a manner that looks almost indistinguishable from writing \texttt{parsley} code.
For example, the \scala{unfold} method on the \scala{Ap} parser contains this snippet, where \scala{pl}, \scala{ql}, and \scala{q} are parsers (\scala{pe} is not a parser, but rather an \scala{Option} value):
% val lefts = {
%   val llr = pl.map(flip) <*> q
%   val rlr = pe.map(f => ql.map(composeH(f))).getOrElse(Empty)
%   llr <|> rlr
% }
\begin{minted}[escapeinside=\%\%]{scala}
val lefts = {
  val llr = pl.map(%\textcolor{gray}{flip}%) <*> q
  val rlr = pe.map(f => ql.map(%\textcolor{gray}{composeH(f)}%)).getOrElse(Empty)
  llr <|> rlr
}
\end{minted}
Other than the capitalised \scala{Empty} constructor, this would be perfectly valid \texttt{parsley} code.

\subsection{Simplifying Parsers Using Parser Laws}\label{sec:simplify-parsers}
Recombining unfolded parsers during left-recursion factoring introduces many necessary, but extraneous ``glue'' combinators.
Even though the transformed parser is semantically correct, it ends up very noisy syntactically.
Consider the resulting parser from factoring out the left-recursion in \scala{expr}:
% lazy val expr: Parsley[String] = chain.postfix(
%   empty | (empty.map(a => b => a + b) | empty <*> expr) <*> string("a")
%     | string("b") | empty
% )(
%   (empty.map(FLIP) <*> expr | pure(ID).map(COMPOSE(a => b => a + b)))
%     .map(FLIP) <*> string("a")
%     | empty | empty
% )
\begin{minted}[escapeinside=\%\%]{scala}
lazy val expr: Parsley[String] = chain.postfix(
  empty | (empty.map(%\textcolor{gray}{a => b => a + b}%) | empty <*> expr) <*> string("a")
    | string("b") | empty
)(
  (empty.map(%\textcolor{gray}{flip}%) <*> expr | pure(%\textcolor{gray}{identity}%).map(%\textcolor{gray}{compose(a => b => a + b)}%))
    .map(%\textcolor{gray}{flip}%) <*> string("a")
    | empty | empty
)
\end{minted}
%
The intent of this parser is completely obfuscated -- it would be unacceptable for the output of the transformation to be left in this form.
For human readability, this parser term must be simplified as much as possible, using domain-specific knowledge about parser combinators.
This is where the deep embedding approach comes to shine; simplifications are easily expressed by pattern matching on \scala{Parser} constructors.

\textcite{willis_staged_2023} note that parser combinators are subject to \emph{parser laws}, which often form a natural simplification in one direction.
In Haskell \texttt{parsley}, \textcite{willis_parsley_2023} uses these parser laws as the basis for high-level optimisations to simplify the structure of the combinator tree.
\texttt{parsley-garnish} uses the same principles to simplify the parser term to become more human-readable.
The two only differ in the purpose of the simplification: whereas Haskell \texttt{parsley} does this to produce an optimised \textsc{ast} to be compiled as code, \texttt{parsley-garnish} simplifies the parser \textsc{ast} to be pretty-printed as text.

\Cref{fig:parser-laws} shows the subset of parser laws utilised by \texttt{parsley-garnish} for parser simplification.
Most of the laws in \cref{fig:parser-laws} have already been shown to hold for Parsley by \textcite{willis_garnishing_2018}; an additional proof for \cref{eqn:alt-fmap-absorb} can be found in \cref{appendix:parser-law-proofs}.

\begin{figure}[htbp]
\centering
\begin{gather}
  % Functor
  \text{\scala{p.map(f).map(g) = p.map(g compose f)}} \label{eqn:functor-comp} \\
  % Applicative functor
  \text{\scala{pure(f) <*> pure(x) = pure(f(x))}} \label{eqn:app-homomorphism} \\
  \text{\scala{pure(f) <*> x = x.map(f)}} \label{eqn:app-fmap} \\
  % Alternative applicative functor
  \text{\scala{empty | u = u}} \label{eqn:alt-left-neutral} \\
  \text{\scala{u | empty = u}} \label{eqn:alt-right-neutral} \\
  \text{\scala{pure(x) | u = pure(x)}} \label{eqn:alt-left-biased-choice} \\
  \text{\scala{empty <*> u = empty}} \label{eqn:alt-empty-absorb} \\
  \text{\scala{empty.map(f) = empty}} \label{eqn:alt-fmap-absorb}
\end{gather}
% I've wanted more fine-grained control, so instead of using cleveref I've manually written out the references -- TAKE CARE to keep them in the same order as the equations
% \caption{Functor~\cref{eqn:functor-comp}, Applicative~\cref{eqn:app-homomorphism,eqn:app-fmap}, and Alternative~\cref{eqn:alt-left-neutral,eqn:alt-right-neutral,eqn:alt-left-biased-choice,eqn:alt-empty-absorb,eqn:alt-fmap-absorb} laws.}
\caption{Functor~(\ref{eqn:functor-comp}), Applicative~(\ref{eqn:app-homomorphism}, \ref{eqn:app-fmap}), and Alternative~(\ref{eqn:alt-left-neutral}--\ref{eqn:alt-fmap-absorb}) laws.}
\label{fig:parser-laws}
\end{figure}

% TODO: vertical spacing here is a bit unsightly, maybe add a \paragraph for these "running example" bits?
In the previous example, it is evident that the most noise results from the \scala{empty} combinators.
These can be eliminated using \cref{eqn:alt-left-neutral,eqn:alt-right-neutral,eqn:alt-empty-absorb,eqn:alt-fmap-absorb}:
% lazy val expr: Parsley[String] = chain.postfix(string("b"))(
%   (pure(identity).map(compose(a => b => a + b))).map(flip) <*> string("a")
% )
\begin{minted}[escapeinside=\%\%]{scala}
lazy val expr: Parsley[String] = chain.postfix(string("b"))(
  (pure(%\textcolor{gray}{identity}%).map(%\textcolor{gray}{compose(a => b => a + b)}%)).map(%\textcolor{gray}{flip}%) <*> string("a")
)
\end{minted}
%
The complicated term in the postfix operator can then be simplified as follows:
% (pure(identity).map(compose(a => b => a + b))).map(flip) <*> string("a")
% pure(compose(a => b => a + b)(identity)).map(flip) <*> string("a")
% pure(flip(compose(a => b => a + b)(identity))) <*> string("a")
% string("a").map(flip(compose(a => b => a + b)(identity)))
\begin{minted}[baselinestretch=1.5,escapeinside=\%\%]{scala}
    (pure(%\textcolor{gray}{identity}%).map(%\textcolor{gray}{compose(a => b => a + b)}%)).map(%\textcolor{gray}{flip}%) <*> string("a")
% \proofstep{\cref{eqn:app-homomorphism,eqn:app-fmap}} %
    pure(%\textcolor{gray}{compose(a => b => a + b)(identity)}%).map(%\textcolor{gray}{flip}%) <*> string("a")
% \proofstep{\cref{eqn:app-homomorphism,eqn:app-fmap}} %
    pure(%\textcolor{gray}{flip(compose(a => b => a + b)(identity))}%) <*> string("a")
% \proofstep{\cref{eqn:app-fmap}} %
    string("a").map(%\textcolor{gray}{flip(compose(a => b => a + b)(identity))}%)
\end{minted}
%
This results in the most simplified form of the parser:
\begin{minted}[escapeinside=\%\%]{scala}
val f: Function = %\textcolor{gray}{flip(compose(a => b => a + b)(identity))}%
lazy val expr: Parsley[String] = chain.postfix(string("b"))(string("a").map(%\textcolor{gray}{f}%))
\end{minted}

\paragraph{Encapsulating boilerplate}
Lawful simplifications are applied akin to peephole optimisations on the recursively defined \scala{Parser} \textsc{adt}.
There are many instances of parsers, which inevitably leads to repetitive and error-prone boilerplate code which exists to simply recurse through each case.
To avoid this, the recursive traversal itself is decoupled from the application of the transformation function.
Although the traversal is still hand-written, the implementation is inspired by the generic traversal patterns offered by Haskell's \texttt{uniplate} library~\cite{mitchell_uniform_2007}.

This is realised as a \scala{transform} method on the \scala{Parser} trait, which takes a partial function and applies it to nodes where it is defined.
The transformation is applied via a bottom-up traversal:
\begin{minted}{scala}
def transform(pf: PartialFunction[Parser, Parser]): Parser = {
  val p = this match {
    case Ap(p, q)      => Ap(p.transform(pf), q.transform(pf))
    case Zipped(f, ps) => Zipped(f, ps.map(_.transform(pf)))
    case Pure(f)       => Pure(f)
    ...
  }
  if (pf.isDefinedAt(p)) pf(p) else p
}
\end{minted}
%
A \scala{rewrite} method can then be defined in terms of \scala{transform}, applying the partial function everywhere and re-applying it until it no longer makes a change.
This has the effect of applying a transformation exhaustively until a normal form is reached.
\begin{minted}{scala}
def rewrite(pf: PartialFunction[Parser, Parser]): Parser = {
  def pf0(p: Parser) = if (pf.isDefinedAt(p)) pf(p).rewrite(pf) else p
  this.transform(pf0)
}
\end{minted}
%
Therefore, any transformation on parsers can be defined without having to worry about recursion boilerplate: the act of traversal itself is fully abstracted away and encapsulated within the \scala{transform} method.
Using \scala{rewrite}, parser simplification can then be expressed in a clean and maintainable manner:
\begin{minted}{scala}
def simplify: Parser = this.rewrite {
  // p.map(f).map(g) == p.map(g compose f)
  case FMap(FMap(p, f), g) => FMap(p, composeH(g, f))
  // u <|> empty == u
  case Choice(u, Empty) => u
  // pure(f) <|> u == pure(f)
  case Choice(Pure(f), _) => Pure(f)
  ...
}
\end{minted}
%
Further design considerations are made to ensure the extensibility and safety of this approach: the \scala{Parser} trait is sealed, which enables compiler warnings if a new \scala{Parser} case is added and the \scala{transform} method is not updated.
Since the traversal is still written by hand rather than generically derived, it is still more prone to error
The traversal could be generically derived rather than written by hand, but this would require the use of an external dependency such as \texttt{shapeless}\footnote{\url{https://github.com/milessabin/shapeless}},
which is overkill for the complexity of the \scala{Parser} \textsc{adt}.

\subsection{Converting Parsers Back to Scalameta Terms}
After parsers have been transformed and simplified, the last step is to convert them back to a textual representation to be applied as a Scalafix patch.
Parsers can be lowered back to \scala{scala.meta.Term} nodes by the inverse of the original \scala{fromTerm} transformation.
The \scala{Parser} trait defines this transformation as the method \scala{term}, using quasiquotes to simplify the construction of the \scala{scala.meta.Term} nodes.
\begin{minted}{scala}
case class Zipped(func: Function, parsers: List[Parser]) extends Parser {
  val term: Term = q"(..${parsers.map(_.term)}).zipped(${func.term})"
}
\end{minted}
%
This term can then be pretty-printed into a string, and applied as a Scalafix patch.

\subsection*{Summary}

\end{document}

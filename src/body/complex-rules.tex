\documentclass[../../main.tex]{subfiles}

\begin{document}

\ourchapter{Using the New Parser \textsc{ast}}\label{sec:complex-rules}
The ability to simplify parsers, as well as normalising their expression arguments, makes it feasible to use the intermediate \scala{Parser} \textsc{ast} for high-level parser transformations.
This \namecref{sec:complex-rules} explores the rules that have been implemented on top of the intermediate \textsc{ast}s, rather than the Scalameta \textsc{ast}, to demonstrate the power of the new \scala{Parser} \textsc{ast} in expressing transformations in a more maintainable and readable way.

\section{Removing Left-Recursion: Revisited}\label{sec:leftrec-revisited}
\Cref{sec:factor-leftrec} left off with a disappointing result for the left-recursion factorisation transformation, producing a mostly unreadable output in \cref{fig:leftrec-example-bad}.
The transformation can now be revisited given the improvements made to the \scala{Parser} \textsc{ast}.
This \namecref{sec:leftrec-revisited} briefly explores some of the changes made to the rule, and the final result of the transformation on the \scala{example} parser.

\subsection{Pretty Parsers}
The need to obtain simpler parser terms was the main driving motivation behind the new \scala{Parser} \textsc{ast}, which now defines the following methods on top of \scala{simplify}:
\begin{itemize}
  \item \scala{normalise}: Simplifies parsers via parser laws and normalises their expression arguments. This is used to check parser equivalence using their canonical forms.
  \item \scala{prettify}: Adds an extra step after normalisation, using a set of ``resugaring'' rules to rebuild the combinators that were desugared during the left-recursion unfolding.
\end{itemize}
%
After the left-recursion transformation, \scala{prettify} is used to make parser terms more readable, before applying the final Scalafix patch.
The following demonstrates the implementation of these methods, as well as a subset of the resugaring rewrite rules:
\begin{minted}{scala}
trait Parser {
  def normalise: Parser = this.simplify.normaliseExprs
  def isEquivalent(other: Parser) = this.normalise == other.normalise
  def prettify: Parser = this.normalise.resugar
  def resugar: Parser = this.rewrite {
    // p.map(x => y => y) <*> q == p ~> q
    case FMap(p, Abs(_, Abs(Var(y, _), Var(z, _)))) <*> q if (y == z) => p ~> q
    // f.curried.map(p) <*> q == (p, q).zipped(f)
    case FMap(p1, Abs(x1, Abs(x2, body))) <*> p2 =>
      Zipped(AbsN(List(x1, x2), body), List(p1, p2))
  }.transform {
    // Scala 2 cannot resolve implicit stringLifts in some positions
    // Replace with explicit 'string' combinator so the compiler does not complain
    case FMap(Str(s, _), f) => FMap(Str(s, implicitSyntax = false), f)
  }
}
\end{minted}

\subsection{Evaluating Expressions}
The higher-order functions \scala{flip} and \scala{compose} are represented as in \cref{fig:higher-order-funcs}, eliminating the need to patch in their definitions as Scala code.
Instead, they get partially evaluated as lambda expressions during normalisation.

The currying of functions passed to \scala{LiftLike} combinators are also expressed with the \scala{Expr} \textsc{ast}, to ensure that they are well-formed during the transformation.
This also significantly reduces the occurrence of \scala{.curried} method calls in the transformed output, which helps Scala's type inference and reduces syntactic noise in the final output.
\begin{minted}{scala}
trait Expr {
  // Curries a lambda expression, flattening into a chain of unary functions
  def curried: Expr = this match {
    case Abs(x, f)        => Abs(x, f.curried)
    case AbsN(x :: xs, f) => Abs(x, AbsN(xs, f).curried)
    case _                => this
  }
}

trait LiftLike extends Parser {
  def unfold() = {
    val curriedFunc = Pure(func match {
      // If the Expr is still opaque, it is treated as before
      case Translucent(term, env) => Translucent(q"($term).curried", env)
      // If statically inspectable, curry the lambda expr properly
      case _ => func.curried
    })
    parsers.foldLeft(curriedFunc)(_ <*> _).unfold
  }
}
\end{minted}

% * Optimisation: normalise leftrec part to see if it comes to empty -- if so, do not inline in the NT case

\subsection{The Improved Rule}
Being able to normalise parsers lets \texttt{parsley-garnish} make more informed decisions about the result of the transformation.
By normalising the \scala{leftRec} portion of the unfolded parser, it can be determined whether the transformation was successful or not:
\begin{itemize}
  \item If \scala{leftRec} resolves to \scala{empty}, the original parser was not left-recursive, so \texttt{parsley-garnish} does not bother rewriting it.
  \item If it simplifies to a \scala{pure(x)}, this indicates a deeper problem which rewriting into the \scala{postfix} combinator cannot solve. This generates a lint error diagnostic instead of an auto-fix.
  \item Otherwise, the parser is left-recursive and can be fixed using the \scala{postfix} combinator. This result is prettified before applying the final patch.
\end{itemize}
%
These cases are implemented in the \scala{transform} method to generate the a Scalafix patch per unfolded parser:
\begin{minted}{scala}
def transform(results: Option[Expr], nonLeftRec: Parser, leftRec: Parser) = {
  val result = results match {
    case None    => Empty
    case Some(t) => Pure(t)
  }

  leftRec.normalise match {
    case Empty   => Patch.empty // not left-recursive, do not rewrite
    case Pure(_) => Patch.lint(LeftRecDerivesEmptyLint) // left-recursive but unfixable
    case _ =>
      val transformed = Postfix(nonLeftRec | results, leftRec).prettify
      Patch.replaceTree(originalTree, transformed.toString)
  }
}
\end{minted}

\subsection*{The Final Result}
Finally, the \scala{example} parser from \cref{sec:factor-leftrec} can be automatically transformed into the following form:
\begin{minted}{scala}
lazy val example: Parsley[String] =
  chain.postfix[String](string("b"))(string("a").map(x1 => x2 => x2 + x1))
\end{minted}
%
This is a \emph{significant} improvement over the original output in \cref{fig:leftrec-example-bad}, and is visually very similar to the ``optimal'' hand-written version in \cref{fig:leftrec-example-good}.
In fact, the two parsers can be proven to be equivalent -- \cref{sec:eval-leftrec} explores this further with some different examples.

\section{Simplify Parsers}
The improved \scala{Parser} \textsc{ast} also grants a new auto-fix rule for free: automatic simplification of parsers.
At a high-level, the rule works as follows:
\begin{itemize}
  \item For each parser, get its prettified form and compare it to the original.
  \item If the result is different, apply the simplified version as a code rewrite.
\end{itemize}
%
The implementation of the entire rule is very straightforward, and only 20 lines long:
\begin{minted}{scala}
class SimplifyParser extends SemanticRule("SimplifyParser") {
  override def fix(implicit doc: SemanticDocument): Patch = {
    getAllParserDefns.map { case ParserDefinition(_, parser, _, originalTree) =>
      val simplifiedParser = parser.prettify
      if (parser.normaliseExprs != simplifiedParser) {
        val simplifiedParserTerm = simplifiedParser.term.syntax
        Patch.replaceTree(originalTree, simplifiedParserTerm)
      } else {
        Patch.empty
      }
    }.asPatch
  }
}
\end{minted}
%
This rule therefore lints for overly complex parsers that can be automatically simplified with parser laws.
It is unclear how useful this rule would be in practice, but it demonstrates the power of the new \scala{Parser} \textsc{ast} in enabling high-level transformations, and is gained with very minimal effort.
For example:
\begin{minted}{scala}
/* Before */  val anise = pure("basil").map(add(_, "coriander"))
/* After */   val anise = pure(add("basil", "coriander"))
\end{minted}
% Subtle detail:
% * During expression normalisation, bound variables may be $\alpha$-renamed
% * So a parser that has not actually changed may still be different when compared to the original
% * So expressions within the original are also normalised -- $\alpha$-equivalence is preserved between normalised expressions
% * Then this doesn not result in changing weird things like variable names

\section{Avoid Parser Redefinitions}
Another rule that can be easily implemented with the new \scala{Parser} \textsc{ast} is to catch cases where a user manually writes out a parser that is already defined in the library.
This is similar in spirit to the previous rule, but makes use of the new \scala{rewrite} and \scala{transform} methods on parsers introduced in \cref{sec:parser-rewrites}, which makes it incredibly convenient to write syntax-directed rewrite rules on parsers.
Expressing high-level rewrites is much less error-prone than working with the Scalameta \textsc{ast} directly, and prevents re-duplication of efforts.
As an example, consider the following rewrite:
\begin{minted}{scala}
parser.rewrite { case ManyP(p <~ sep) => EndBy(p, sep) }
\end{minted}
%
This catches a case where a user writes a parser in the form of \scala{many(p <~ sep)}, which is already defined in \texttt{parsley} as \scala{endBy(p, sep)}.
Compare this to the equivalent pattern match if working with the low-level \textsc{ast} directly:
\begin{minted}{scala}
tree.collect {
  case Term.Apply.After_4_6_0(
    manyMatcher(_),
    Term.ArgClause(
      List(Term.ApplyInfix.After_4_6_0(
        Term.Name("p"),
        Term.Name("<~"),
        Type.ArgClause(Nil),
        Term.ArgClause(List(Term.Name("sep")), None)
    )), None)) => q"endBy(p, sep)"
}
\end{minted}
%
This rule is likely to be much more useful in practice than \emph{Simplify Parsers}, serving as a pedagogical tool to guide users towards using the library's higher-level combinators.

% ** although still annoying for e.g. def countMany(p: Parsley[_]): Parsley[Int] = p.foldLeft(0)((n, _) => n + 1)    <---- still no good way to pattern match expr given that "n + 1" is translucent, easier to just reify this back to scala.meta.term and then low-level pattern match

% \section{Convert to Parser Bridge}
% \TODO{
% * This would be cool, idk if I have time though, but this should also piggyback off of Func
% * the pos bridges do not actually exist, so we can ignore that case and just say its too much code synthesis
% * indicate limitations that this will only work if the ADT is defined in the same file, in order to extend it
% }

\section*{Summary}

\end{document}

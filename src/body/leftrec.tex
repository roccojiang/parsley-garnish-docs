\documentclass[../../main.tex]{subfiles}

\begin{document}

\ourchapter{Removing Left-Recursion}\label{sec:factor-leftrec}

\emph{Left-recursive} grammar rules are a common pattern to represent left-associativity.
Take for example the following definition of a left-associative addition operator:
\begin{equation*}
\langle \mathit{expr} \rangle ::= \langle \mathit{expr} \rangle \; \text{`+'} \; \langle \mathit{term} \rangle \enspace | \enspace \langle \mathit{term} \rangle
\end{equation*}
%
Since the first production of $\langle \mathit{expr} \rangle$ is itself, this rule is said to be left-recursive.
This poses a problem for recursive-descent parsers, such as those that \texttt{parsley} produces:
it will try to parse $\langle \mathit{expr} \rangle$ by first trying to parse $\langle \mathit{expr} \rangle$, and so on, resulting in an unproductive infinite loop.

Although it is possible to address the issue by transforming the grammar with algorithms such as Paull's algorithm~\cite{moore_removing_2000},
in the context of parser combinators this is considered an anti-pattern by \textcite{willis_design-haskell_2021}.
They argue that this transformation obscures the original intent of the grammar, and exposes lower-level implementation details when this can be abstracted behind a combinator.
Instead, they propose that the idiomatic method to handle left-recursion in parser combinators is to use the \scala{chain} family of combinators~\cite{fokker_functional_1995}.
These combinators encapsulate the behaviour of right-associating left-recursive rules and correcting the result back to a left-associative form.

Left-recursion often comes as a nasty surprise for novice users naÃ¯vely translating \textsc{bnf} grammars into parser implementations -- this issue is not unique to parser combinators, but also extends to many popular parser generators that use recursive-descent.
Thus, it would be beneficial to provide a linting rule for \texttt{parsley} that can warn users when parsers are left-recursive.
In fact, \texttt{parsley} 5.0 is already planned to introduce a \scala{detectDivergence} combinator, which performs \emph{dynamic} analysis to detect unproductive looping at runtime.
Therefore, \texttt{parsley-garnish} could complement this functionality with an auto-fix rule to refactor left-recursive parsers to use \texttt{parsley}'s idiomatic \scala{chain} combinators.
% TODO: could compare what the static vs dynamic analyses can detect?

\paragraph{Running example}
The following left-recursive parser and its transformation into a non-left-recursive form will be used as an example for this \namecref{sec:factor-leftrec}:
\begin{minted}{scala}
lazy val example: Parsley[String] = (example, string("a")).zipped(_ + _) | string("b")
\end{minted}
%
The \scala{example} parser intends to express the following simple grammar expressed using left-recursion. The goal is to refactor \scala{example} so that it retains the intended semantics, but is transformed into a parser that \texttt{parsley} can handle correctly.
\begin{equation*}
  \langle \mathit{example} \rangle ::= \langle \mathit{example} \rangle \; \text{``a''} \enspace | \enspace \text{``b''}
\end{equation*}

% \begin{minted}{scala}
% def postfix[A](p: Parsley[A], op: =>Parsley[A => A]): Parsley[A] =
%   lazy val rest: Parsley[A => A] = (op, rest).zipped(_ andThen _) <|> pure(identity[A])
%   p <**> rest
% \end{minted}
% \begin{minted}{haskell}
% postfix :: Parser a -> Parser (a -> a) -> Parser a
% postfix p op = p <**> rest
%   where rest = flip (.) <$> op <*> rest <|> pure id
% \end{minted}

\section{The Left-Recursion Factoring Transformation}
\texttt{parsley-garnish} bases its left-recursion factoring transformation on the work of \textcite{baars_leftrec_2004}, adapted to fit the \textsc{peg} semantics of \texttt{parsley}.
At a high-level, the transformation involves ``unfolding'' each non-terminal production into three parts:
\begin{itemize}
  \item \scala{results}: The semantic actions of the parser, if it can derive the empty string. Conceptually, this has type \scala{Option[A]} where \scala{A} is the type of the result.
  \item \scala{nonLeftRec}: The non-left-recursive part of the parser that does not derive the empty string. This will have some type \scala{Parsley[A]}.
  \item \scala{leftRec}: The left-recursive call, which in the general left-recursive case, corresponds to a repeated postfix operator of type \scala{Parsley[A => A]}. This is a function which requires the semantics of the left-recursive non-terminal argument.
\end{itemize}
%
This transformation is applied in-order to each parser in the source file, replacing the original parser with its factored form if it was left-recursive.
An unfolded parser is recombined using \scala{chain.postfix}: this combinator encapsulates the general form of left-associative parsing, and most other iterative combinators can be derived from it~\cite{willis_parsley_2024}.
% def postfix[A](p: Parsley[A])(op: => Parsley[A => A]): Parsley[A]
\begin{minted}{scala}
val result = results match {
  case None    => empty
  case Some(x) => pure(x)
}
val transformed = chain.postfix(nonLeftRec | results)(leftRec)
\end{minted}

\section{Necessary Infrastructure}\label{sec:leftrec-infra}
The comparatively simple linting rules discussed in the previous \namecref{sec:simple-rules} were implemented by directly inspecting the generic Scala \textsc{ast} provided by Scalafix.
However, even though \texttt{parsley} programs are written in Scala, it is important to remember that \texttt{parsley} is a \textsc{dsl} borrowing Scala as a host language.
Domain-specific transformations like left-recursion factoring are therefore naturally defined as transformations on the \texttt{parsley} \textsc{ast}, at a higher level of abstraction than the generic Scala \textsc{ast}.
Thus, this \namecref{sec:leftrec-infra} discusses the extra infrastructure used to support the left-recursion factoring transformation:
\begin{itemize}
  \item \cref{sec:parser-ast-motivation} motivates the idea of using an intermediate \textsc{ast} representation for parsers, distinct from the general-purpose Scala \textsc{ast}.
  \item \cref{sec:lifting-parsers} shows how the \textsc{ast} of a Scala source file is converted into this intermediate representation, whereas \cref{sec:lowering-parsers} discusses how this is converted back into Scala code so that it can be applied as a Scalafix patch.
\end{itemize}

\subsection{An Intermediate \textsc{ast}}\label{sec:parser-ast-motivation}
The transformations described by \textcite{baars_leftrec_2004} require an explicit representation of the grammar and production rules so that they can be inspected and manipulated before generating code.
They achieve this by representing parsers as a deep-embedded datatype in the form of an intermediate \textsc{ast}, in a similar manner to \texttt{parsley}.

Since \texttt{parsley-garnish} is a linter, by nature, it has access to an explicit grammar representation in the form of the full \scala{scala.meta.Tree} \textsc{ast} of the source program.
However, this datatype represents general-purpose abstract Scala syntax, rather than the abstract syntax of a specialised parser combinator \textsc{dsl}.
This makes it not well-suited for performing domain-specific operations over the \textsc{ast}.

Take for example the task of combining two \textsc{ast} nodes \scala{Term.Name("p")} and \scala{Term.Name("q")}, representing named parsers \scala{p} and \scala{q}, with the combinator \scala{<*>} (pronunced ``ap'').
This operation can be concisely expressed with Scalameta quasiquotes, rather than manually writing out the full explicit \textsc{ast}:
\begin{minted}{scala}
q"p <*> q" ==
  Term.ApplyInfix(
    Term.Name("p"),
    Term.Name("<*>"),
    Type.ArgClause(Nil),
    Term.ArgClause(List(Term.Name("q")), None)
  )
\end{minted}
However, the  operation of inspecting the individual parsers \scala{p} and \scala{q} is not as straightforward.
Although quasiquotes can be used as extractor patterns in pattern matching, this usage is discouraged due to limitations in their design that makes it easy to accidentally introduce match errors\footnote{\url{https://scalameta.org/docs/trees/guide.html#with-quasiquotes-1}}.
Thus, extracting the parsers necessitates a long-winded pattern match like so:
\begin{minted}{scala}
val ap = SymbolMatcher.normalized("parsley.Parsley.`<*>`")

def deconstructAp(parser: Term) = parser match {
  case Term.ApplyInfix(p, ap(_), _, Term.ArgClause(List(q), _)) => (p, q)
}
\end{minted}
This involves dealing with abstract general-purpose syntax constructs like \scala{Term.ApplyInfix}, which are low-level details not relevant to the task of manipulating parsers.
Although this is not an issue for simple one-off transformations, for more specialised transformations like left-recursion factoring, it would be desirable to abstract away from these low-level syntactic details.
This motivates the need for an higher-level, intermediate \textsc{ast} representation that is more specialised to the domain of parser combinators.

\subsubsection{The Parser \textsc{adt}}
\texttt{parsley-garnish} therefore takes a similar approach as \textcite{baars_leftrec_2004} and \texttt{parsley} itself, building an intermediate \textsc{ast} as a deep-embedded parser combinator tree.
\Cref{fig:parser-adt} shows how this is implemented as a \scala{Parser} algebraic data type (\textsc{adt}).
All \scala{Parser} types represent \texttt{parsley} combinators, with the sole exception of \scala{NonTerminal} to represent references to named parsers.

\begin{figure}[htbp]
\begin{minted}{scala}
trait Parser
case class NonTerminal(ref: Symbol) extends Parser
case class Pure(x: Term) extends Parser
case object Empty extends Parser
case class <*>(p: Parser, q: Parser) extends Parser
case class <|>(p: Parser, q: Parser) extends Parser
\end{minted}
\caption{A subset of the core combinators in the \scala{Parser} \textsc{adt}.}
\label{fig:parser-adt}
\end{figure}

\paragraph{Deconstructing parsers}
Scala allows users to define symbolic class names (as evidenced by the definitions of \scala{<*>} and \scala{<|>} in \cref{fig:parser-adt}), and provides syntactic sugar to pattern match on these constructors using infix notation.
This results in a very natural and readable pattern matching syntax:
\begin{minted}{scala}
def deconstructAp(parser: Parser) = parser match {
  case p <*> q => (p, q)
}
\end{minted}

\paragraph{Constructing parsers}
Defining infix operators as extension methods on the \scala{Parser} trait provides a similar syntactic sugar for constructing parsers:
\begin{minted}{scala}
extension (p: Parser) {
  def <*>(q: Parser) = <*>(p, q)
  def |(q: Parser) = <|>(p, q)
  def map(f: Term) = FMap(p, f)
}
extension (ps: List[Parser]) {
  def zipped(f: Term) = Zipped(f, ps)
}
\end{minted}
%
This makes the syntax for writing \scala{Parser} terms feel natural and similar to writing \texttt{parsley} code.
For example, notice how constructing the \emph{code} representation of the \scala{example} parser resembles how the original parser itself would be written:
\begin{minted}{scala}
val EXAMPLE = NonTerminal(Sym(Term.Name("example").symbol))  

// val example: Parsley[String] =     (example,  string("a")).zipped(  _ + _ ) | string("b")
   val example: Parser          = List(EXAMPLE,     Str("a")).zipped(q"_ + _") |    Str("b")
\end{minted}

% Instead, represent parsers as an algebraic data type \textsc{adt} in the same way that Parsley itself uses a deep embedding to represent combinators as objects.
% Methods on these objects can then be used to manipulate them, and the resulting object can still be pattern matched, maintaining the static inspectability of the parsers.
% So then it's just like writing parsers in Parsley itself: \scala{p <*> q} constructs a \scala{Ap(p, q)} node which can still be pattern matched on.
% And similar to Parsley, representing everything as objects makes it easy to optimise using pattern matching on constructors.
% This representation also then gives us for free the implementation for lint rules such as \emph{Simplify Complex Parsers} rule, which applies parser laws to simplify parsers.

\subsection{Lifting to the Intermediate Parser \textsc{ast}}\label{sec:lifting-parsers}
Converting the raw Scala \textsc{ast} to this intermediate parser combinator \textsc{ast} requires the following basic operations:
\begin{enumerate}
  \item Identifying all named parsers defined in the source program -- these correspond to non-terminal symbols in the grammar.
  \item Lifting the definition each parser into the intermediate \textsc{ast}, i.e. a \scala{Parser} object.
  \item Collecting these into a map to represent the high-level grammar -- the unique symbol of each named parser is mapped to its corresponding \scala{Parser} object, along with extra metadata required for the transformation.
\end{enumerate}
%
Most importantly, this metadata includes a reference to a parser's original node in the Scala \textsc{ast}, so lint diagnostics or code rewrites can be applied to the correct location in the source file:
\begin{minted}{scala}
case class ParserDefn(name: Term.Name, parser: Parser, tpe: Type.Name, originalTree: Term)
\end{minted}

\subsubsection{Identifying Named Parsers}
Finding \textsc{ast} nodes corresponding to the definition sites of named parsers involves pattern matching on \scala{val}, \scala{var}, and \scala{def} definitions with a type inferred to be some \scala{Parsley[_]}.
This type information is accessed by querying the Scalafix semantic \textsc{api} for the node's symbol information.
Consider the labelled \textsc{ast} structure of the \scala{example} parser:
\begin{minted}{scala}
// lazy val example: Parsley[String] = (example, string("a")).zipped(_ + _) | string("b")
// ^^^^     ^^^^^^^  ^^^^^^^^^^^^^^^   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
// mods      pats        decltpe                             rhs

val exampleTree = Defn.Val(
  mods = List(Mod.Lazy()),
  pats = List(Pat.Var(Term.Name("example"))),
  decltpe = Some(
    Type.Apply(Type.Name("Parsley"), Type.ArgClause(List(Type.Name("String"))))
  ),
  rhs = Term.ApplyInfix(...)
)
\end{minted}
%
% In this case, the type of \scala{example} is explicitly annotated by the user since this is required for recursive definitions.
% However in general, users will not explicitly annotate the types of their parsers, allowing the Scala compiler to infer the type.
Note that the \scala{decltpe} field refers to the \emph{syntax} of the explicit type annotation, not the \emph{semantic} information the variable's inferred type.
Therefore, this field will not always be present, so in the general case, the type must be queried via a symbol information lookup:
\begin{minted}{scala}
exampleTree match {
  case Defn.Val(_, List(Pat.Var(varName)), _, body) =>
    println(s"qualified symbol = ${varName.symbol}")
    // Query the symbol information of the variable name, and get its type signature
    varName.symbol.info.get.signature match {
      // Scalameta treats this as a zero-arg method, so the relevant part is its return type
      case MethodSignature(_, _, returnType) =>
        println(s"type = $returnType")
        println(s"structure of type object = ${returnType.structure}")
    }
}
// qualified symbol = path/to/package/ObjectName.example.
// type = Parsley[String]
// structure of type object = TypeRef(
//   NoType,
//   Symbol("parsley/Parsley#"),
//   List(TypeRef(NoType, Symbol("scala/Predef.String#"), List()))
// )
\end{minted}
Seeing that the type of this \textsc{ast} node is \scala{Parsley[String]}, \texttt{parsley-garnish} can then proceed to convert the \scala{rhs} term into a \scala{Parser} \textsc{adt} object.
The map entry uses the fully qualified symbol for \scala{example} as the key, and the lifted \scala{Parser} object as the value.

% Thus, a full traversal through the source file builds a map of all named parsers, representing all non-terminals in the grammar defined within that file.

\subsubsection{Converting Scalameta Terms to the Parser \textsc{adt}}
Having identified the \textsc{ast} nodes which represent parsers, they need to be transformed into the appropriate \scala{Parser} representation.
This involves pattern matching on the \scala{scala.meta.Term} to determine which parser combinator it represents, and then constructing the appropriate \scala{Parser} instance.

Each \scala{Parser} defines a partial function \scala{fromTerm} to instantiate a parser from the appropriate \scala{scala.meta.Term}.
These \scala{fromTerm} methods perform the menial work of pattern matching on the low-level syntactic constructs of the Scala \textsc{ast}.
All \scala{fromTerm} methods are combined to define the \scala{toParser} extension method on \scala{scala.meta.Term} -- this is where \textsc{ast} nodes are lifted to their corresponding \scala{Parser} representation.

The pattern matching example from \cref{sec:parser-ast-motivation} makes a reappearance in the definition of \scala{Ap.fromTerm}, where the arguments to the \scala{<*>} combinator are instead recursively lifted to \scala{Parser} objects:
% Use Scalafix's \scala{SymbolMatcher} to match tree nodes that resolve to a specific set of symbols.
% This makes use of semantic information from SemanticDB, so we are sure that a \scala{<*>} is actually within the \scala{parsley.Parsley} package, rather than some other function with the same name.
% This is much more robust compared to HLint, which suffers from false positives due to its reliance on syntactic information only.
\begin{minted}{scala}
// Type signatures in Parsley:
// p: Parsley[A => B], q: =>Parsley[A], p <*> q: Parsley[B]
case class Ap(p: Parser, q: Parser) extends Parser
object Ap {
  // Match the specific symbol for parsley's <*> combinator
  val matcher = SymbolMatcher.normalized("parsley.Parsley.`<*>`")

  def fromTerm: PartialFunction[Term, Ap] = {
    // Pattern match succeeds only if the term has the structure 'p <*> q'
    case Term.ApplyInfix(p, matcher(_), _, Term.ArgClause(List(q), _)) =>
      Ap(p.toParser, q.toParser)
  }
}
\end{minted}
%
Where a combinator takes a non-parser argument, this is treated as a black box and kept as a raw \textsc{ast} node of type \scala{scala.meta.Term}:
\begin{minted}{scala}
// x: A, pure(x): Parsley[A]
case class Pure(x: Term) extends Parser
object Pure {
  val matcher = SymbolMatcher.normalized("parsley.ParsleyImpl.pure")

  def fromTerm: PartialFunction[Term, Pure] = {
    // expr is an opaque AST node that can't be further inspected
    case Term.Apply(matcher(_), Term.ArgClause(List(expr), _)) => Pure(expr)
  }
}
\end{minted}

\subsubsection{Building the Grammar Map}
The overall process of converting the source file \textsc{ast} to a high-level map of the grammar can therefore be expressed as a single traversal over the \textsc{ast}:
\begin{minted}{scala}
// Encapsulate all valid pattern matches into a single extractor object
object VariableDecl {
  def unapply(tree: Tree): ParserDefn = tree match {
    // isParsleyType uses symbol info to check if variable type is Parsley[_]
    case Defn.Val(_, List(Pat.Var(varName)), _, body) if isParsleyType(varName) =>
      // If the pattern match is successful, convert the definition body to a Parser
      // Collect metadata and bundle into a parser definition object
      ParserDefn(
        name = varName,
        parser = body.toParser,
        tpe = getParsleyType(varName),
        originalTree = body
      )
    // ... similar cases for Defn.Var and Defn.Def
  }
}

val nonTerminals: Map[Symbol, ParserDefn] = doc.tree.collect {
  // Every AST node that satisfies the pattern match is added to the map
  case VariableDecl(parserDef) => parserDefn.name.symbol -> parserDef
}.toMap
\end{minted}

\subsection{Lowering Back to the Scalameta \textsc{ast}}\label{sec:lowering-parsers}
After all necessary transformations have been applied to parser terms, the final step is to convert them back to a textual representation to be applied as a Scalafix patch.
Parsers can be lowered back to \scala{scala.meta.Term} nodes by the inverse of the original \scala{fromTerm} transformation.
The \scala{Parser} trait defines this transformation as the method \scala{term}, using quasiquotes to simplify the construction of the \scala{scala.meta.Term} nodes.
For example:
\begin{minted}{scala}
case class Zipped(func: Function, parsers: List[Parser]) extends Parser {
  val term: Term = q"(..${parsers.map(_.term)}).zipped(${func.term})"
}
\end{minted}
%
This term can then be pretty-printed into a string, and applied as a Scalafix patch.

\subsection{Implementing the Left-Recursion Transformation}
\TODO{TODO \\}

Core combinators: \scala{NonTerminal}, \scala{Pure}, \scala{Empty}, \scala{Ap}, \scala{Choice}.
Combinators like \scala{String} are theoretically core combinators but they represent boring cases.
Some composite combinators are supported, and desugared into the core combinators.

\TODO{
Can derive empty string? (good resource from packrat parsing paper)
pure(x) -- yes, semantic action is x
empty -- no
p <|> q -- if p or q can derive empty, peg is ordered so semantic action is pe if it can derive empty, else qe
p <*> q -- if p and q can derive empty, semantic action is pe(qe) due to pure(f) <*> pure(x) == pure(f(x)) law
string -- only if given argument "", but this also illegal in parsely -- explicitly triggers a runtime error, so basically no
    [error] java.lang.IllegalArgumentException: requirement failed: `string` may not be passed the empty string (`string("")` is meaningless, perhaps you meant `pure("")`?)
char -- no (not implemented as a core comb, should do that)
item -- no (not implemented as a core comb, should do that?)
many(p) -- yes (not implemented properly?) -- semantic action is empty list??
some(p) -- if p can derive empty (not a primitive, defined in terms of many -- p <::> many(p))
NT -- if referenced rule can derive empty
}

\subsubsection{Defining Utility Functions}
The transformation requires the use of three higher-order functions:
\begin{itemize}
  \item The identity function \scala{identity[A]: A => A} is defined in the standard library.
  \item The flip function reverses the order of arguments applied to a function. This isn't defined in the standard library, so it must be defined manually.
  \item Function composition is defined in the standard library, but a more versatile curried version is required by the transformation, so it is also defined manually.
\end{itemize}
%
Therefore, \texttt{parsley-garnish} will insert the following definitions into the source file as a patch:
\begin{minted}{scala}
  def flip[A, B, C](f: A => B => C)(x: B)(y: A): C = f(y)(x)
  def compose[A, B, C](f: B => C)(g: A => B)(x: A): C = f(g(x))
\end{minted}
%
This brings these higher-order functions into scope, allowing the transformed code to make use of it.

The \scala{unfold} method is defined for every single combinator in the \scala{Parser} \textsc{adt}.
Most important is the \scala{Ap} combinator, which is \texttt{parsley-garnish}'s primitive for composing parsers.
%
\begin{minted}{scala}
case class Ap(p: Parser, q: Parser) extends Parser {
  def unfold: UnfoldedParser = {
    val UnfoldedParser(pe, pn, pl) = p.unfold
    val UnfoldedParser(qe, qn, ql) = q.unfold

    val result =
      if (pe.isDefined && qe.isDefined) Some(q"${pe.get}(${qe.get})")
      else None

    val lefts = {
      val llr = pl.map(q"flip") <*> q
      val rlr = pe.map(q"ql.map(compose)").getOrElse(Empty)
      llr <|> rlr
    }

    val nonLefts = {
      val lnl = pn <*> q
      val rnl = pe.map(q"f => qn.map(f)").getOrElse(Empty)
      lnl <|> rnl
    }

    UnfoldedParser(result, nonLefts, lefts)
  }
}
\end{minted}

\subsubsection{Success...?}
Running the transformation on the \scala{example} parser yields the output in \cref{fig:leftrec-example-bad}.
%
\begin{figure}[htbp]
\begin{minted}{scala}
def flip[A, B, C](f: A => B => C)(x: B)(y: A): C = f(y)(x)
def compose[A, B, C](f: B => C)(g: A => B)(x: A): C = f(g(x))

lazy val example: Parsley[String] = chain.postfix(
  empty | (empty.map((_ + _).curried) | empty <*> example) <*> string("a")
    | string("b") | empty
)(
  (empty.map(flip) <*> example | pure(identity).map(compose((_ + _).curried)))
    .map(flip) <*> string("a")
    | empty | empty
)
\end{minted}
\caption{The initial attempt at factoring out left-recursion from the \scala{example} parser.}
\label{fig:leftrec-example-bad}
\end{figure}

This is... disappointing, to say the least.
There are \emph{many} things wrong with the transformed output:
\begin{itemize}
  \item The parser is horrendously complex and unreadable, its intent entirely obfuscated in a sea of combinators. It's especially frustrating that there are so many \scala{empty} combinators, when \scala{p | empty} and \scala{empty | p} are both actually just equivalent to \scala{p}.
  \item Having to define the \scala{flip} and \scala{compose} functions is not ideal, but inlining them as lambdas would make the code even worse.
  \item Even worse, the parser does not even typecheck -- unlike classical Hindley-Milner-based type systems, Scala only has \emph{local} type inference~\cite{cremet_core_2006}. As a result, the compiler is unable to correctly infer correct types for \scala{flip} and also asks for explicit type annotations in the lambda \scala{(_ + _).curried}.
\end{itemize}
% foreshadowing lol
This result is discouraging especially because it is not impossible to factor out the left-recursion in a nice manner.
A hand-written equivalent using \scala{postfix} would resemble the concisely defined parser in \cref{fig:leftrec-example-hand}.
There is still hope, though -- if the \scala{empty} combinators can be removed and something is done about the higher-order functions, perhaps \cref{fig:leftrec-example-bad} could be salvaged into something that looks more like the human-written version.

\begin{figure}[htbp]
\begin{minted}{scala}
lazy val example: Parsley[String] = chain.postfix(string("b"))(string("a").as(_ + "a"))
\end{minted}
\caption{An idiomatic way to express the \scala{example} parser using \scala{chain.postfix}.}
\label{fig:leftrec-example-hand}
\end{figure}

\end{document}
